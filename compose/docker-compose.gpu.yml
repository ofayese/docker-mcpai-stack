# Docker MCP Stack - GPU Configuration
# Overrides for GPU-accelerated inference

version: "3.9"

services:
  # GPU-enabled model runner
  model-runner:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: ["gpu"]
    environment:
      - RUNNER_HTTP_ADDR=0.0.0.0:8080
      - MODEL_CACHE=/models
      - CONFIG_PATH=/config
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - LLAMA_SERVER_VARIANT=cuda
    profiles: ["gpu"]

  # GPU-accelerated worker for embeddings
  mcp-worker:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: ["gpu"]
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    profiles: ["gpu"]
