# Docker MCP Stack - GPU Configuration
# Overrides for GPU-accelerated inference

version: "3.9"

# Use anchors for DRY and modern Compose
x-runtime-gpu: &runtime_gpu
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: ["gpu"]

services:
  # GPU-enabled model runner
  model-runner:
    <<: *runtime_gpu
    environment:
      - RUNNER_HTTP_ADDR=0.0.0.0:8080
      - MODEL_CACHE=/models
      - CONFIG_PATH=/config
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      - LLAMA_SERVER_VARIANT=cuda
    profiles: ["gpu"]

  # GPU-accelerated worker for embeddings
  mcp-worker:
    <<: *runtime_gpu
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
    profiles: ["gpu"]
